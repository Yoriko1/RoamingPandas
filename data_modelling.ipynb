{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Preprocessed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into dataframe\n",
    "df_bath = pd.read_csv('preprocessed_dataset_bath.csv')\n",
    "df_sqft = pd.read_csv('preprocessed_dataset_sqft.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training - Bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate rows with NaN values\n",
    "df_bath_nan = df_bath[df_bath.isna().any(axis=1)]\n",
    "\n",
    "# Separate rows without NaN values\n",
    "df_bath_without_nan = df_bath[df_bath.notna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5733333333333334\n",
      "F1 Score: 0.5461869513677541\n",
      "Recall: 0.5733333333333334\n",
      "Precision: 0.5366242112431929\n"
     ]
    }
   ],
   "source": [
    "# Split into features (X) and target variable (y)\n",
    "X = df_bath_without_nan.drop(columns=['BATH'])\n",
    "y = df_bath_without_nan['BATH']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier with k=5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "f1 = f1_score(y_test, y_pred,average='weighted', zero_division= np.nan)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred,average='weighted')\n",
    "precision = precision_score(y_test, y_pred,average='weighted', zero_division= np.nan)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6577777777777778\n",
      "F1 Score: 0.6593987039716467\n",
      "Recall: 0.6577777777777778\n",
      "Precision: 0.6654351256647547\n"
     ]
    }
   ],
   "source": [
    "# Split into features (X) and target variable (y)\n",
    "X = df_bath_without_nan.drop(columns=['BATH'])\n",
    "y = df_bath_without_nan['BATH']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "f1 = f1_score(y_test, y_pred,average='weighted', zero_division= np.nan)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred,average='weighted')\n",
    "precision = precision_score(y_test, y_pred,average='weighted', zero_division= np.nan)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6133333333333333\n",
      "F1 Score: 0.5848345244676091\n",
      "Recall: 0.6133333333333333\n",
      "Precision: 0.6116510687728469\n"
     ]
    }
   ],
   "source": [
    "# Split into features (X) and target variable (y)\n",
    "X = df_bath_without_nan.drop(columns=['BATH'])\n",
    "y = df_bath_without_nan['BATH']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an SVM model with a linear kernel\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred,average='weighted', zero_division= np.nan)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred,average='weighted')\n",
    "precision = precision_score(y_test, y_pred,average='weighted', zero_division= np.nan)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training - Square Feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate rows with NaN values\n",
    "df_sqft_nan = df_sqft[df_sqft.isna().any(axis=1)]\n",
    "\n",
    "# Separate rows without NaN values\n",
    "df_sqft_without_nan = df_sqft[df_sqft.notna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6446540880503144\n",
      "F1 Score: 0.7839388145315488\n",
      "Recall: 0.6446540880503144\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Split into features (X) and target variable (y)\n",
    "X = df_sqft_without_nan.drop(columns=['PROPERTYSQFT'])\n",
    "y = df_sqft_without_nan['PROPERTYSQFT']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the KNN classifier with k=5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Log transformation (using log1p to handle potential 0 values)\n",
    "log_actuals = np.log1p(y_test)\n",
    "log_predictions = np.log1p(y_pred)\n",
    "\n",
    "# Define tolerance within 5%\n",
    "tolerances = .05 * log_actuals\n",
    "\n",
    "# Calculate \"true positives\", \"false positives\", and \"false negatives\"\n",
    "within_tolerance = np.abs(log_actuals - log_predictions) <= tolerances\n",
    "\n",
    "# Create binary classifications\n",
    "binary_actuals = np.ones_like(log_actuals)  # All actuals are \"positive\"\n",
    "binary_predictions = within_tolerance.astype(int)  # 1 if within tolerance, 0 otherwise\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "f1 = f1_score(binary_actuals, binary_predictions,average='weighted', zero_division= np.nan)\n",
    "accuracy = accuracy_score(binary_actuals, binary_predictions)\n",
    "recall = recall_score(binary_actuals, binary_predictions,average='weighted', zero_division= np.nan)\n",
    "precision = precision_score(binary_actuals, binary_predictions,average='weighted', zero_division= np.nan)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7861635220125787\n",
      "F1 Score: 0.8802816901408451\n",
      "Recall: 0.7861635220125787\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Split into features (X) and target variable (y)\n",
    "X = df_sqft_without_nan.drop(columns=['PROPERTYSQFT'])\n",
    "y = df_sqft_without_nan['PROPERTYSQFT']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Log transformation (using log1p to handle potential 0 values)\n",
    "log_actuals = np.log1p(y_test)\n",
    "log_predictions = np.log1p(y_pred)\n",
    "\n",
    "# Define tolerance within 5%\n",
    "tolerances = .05 * log_actuals\n",
    "\n",
    "# Calculate \"true positives\", \"false positives\", and \"false negatives\"\n",
    "within_tolerance = np.abs(log_actuals - log_predictions) <= tolerances\n",
    "\n",
    "# Create binary classifications\n",
    "binary_actuals = np.ones_like(log_actuals)  # All actuals are \"positive\"\n",
    "binary_predictions = within_tolerance.astype(int)  # 1 if within tolerance, 0 otherwise\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "f1 = f1_score(binary_actuals, binary_predictions,average='weighted', zero_division= np.nan)\n",
    "accuracy = accuracy_score(binary_actuals, binary_predictions)\n",
    "recall = recall_score(binary_actuals, binary_predictions,average='weighted', zero_division= np.nan)\n",
    "precision = precision_score(binary_actuals, binary_predictions,average='weighted', zero_division= np.nan)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5974842767295597\n",
      "F1 Score: 0.7480314960629921\n",
      "Recall: 0.5974842767295597\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Split into features (X) and target variable (y)\n",
    "X = df_sqft_without_nan.drop(columns=['PROPERTYSQFT'])\n",
    "y = df_sqft_without_nan['PROPERTYSQFT']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an SVM model with a linear kernel\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Log transformation (using log1p to handle potential 0 values)\n",
    "log_actuals = np.log1p(y_test)\n",
    "log_predictions = np.log1p(y_pred)\n",
    "\n",
    "# Define tolerance within 5%\n",
    "tolerances = .05 * log_actuals\n",
    "\n",
    "# Calculate \"true positives\", \"false positives\", and \"false negatives\"\n",
    "within_tolerance = np.abs(log_actuals - log_predictions) <= tolerances\n",
    "\n",
    "# Create binary classifications\n",
    "binary_actuals = np.ones_like(log_actuals)  # All actuals are \"positive\"\n",
    "binary_predictions = within_tolerance.astype(int)  # 1 if within tolerance, 0 otherwise\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "f1 = f1_score(binary_actuals, binary_predictions,average='weighted', zero_division= np.nan)\n",
    "accuracy = accuracy_score(binary_actuals, binary_predictions)\n",
    "recall = recall_score(binary_actuals, binary_predictions,average='weighted', zero_division= np.nan)\n",
    "precision = precision_score(binary_actuals, binary_predictions,average='weighted', zero_division= np.nan)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict missing data using best scoring model\n",
    "Random Forest performed best for both # of baths and sqft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "      <th>BEDS</th>\n",
       "      <th>BATH</th>\n",
       "      <th>SUBLOCALITY_ENCODED</th>\n",
       "      <th>TYPE_ENCODED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55000000</td>\n",
       "      <td>7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>689000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2250000</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1489000</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>65000000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4776</th>\n",
       "      <td>555000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>2000000</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>799000</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>4750000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>789000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PRICE  BEDS  BATH  SUBLOCALITY_ENCODED  TYPE_ENCODED\n",
       "4     55000000     7   9.0                  1.0           2.0\n",
       "11      689000     3   2.0                  2.0           2.0\n",
       "27     2250000    12   6.0                  4.0           4.0\n",
       "68     1489000     6   4.0                  2.0           4.0\n",
       "69    65000000     3   6.0                  1.0           2.0\n",
       "...        ...   ...   ...                  ...           ...\n",
       "4776    555000     3   2.0                  2.0           9.0\n",
       "4780   2000000     8   4.0                  3.0           4.0\n",
       "4783    799000     6   4.0                 11.0           4.0\n",
       "4788   4750000     3   4.0                  4.0           3.0\n",
       "4790    789000     3   2.0                  4.0           0.0\n",
       "\n",
       "[302 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into features (X) and target variable (y)\n",
    "X = df_bath_without_nan.drop(columns=['BATH'])\n",
    "y = df_bath_without_nan['BATH']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.067, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "test = df_bath_nan.drop(columns=['BATH'])\n",
    "\n",
    "y_pred = rf_model.predict(test)\n",
    "\n",
    "df_bath_nan['BATH'] = y_pred\n",
    "df_bath_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate along rows (axis=0)\n",
    "df_bath_concat = pd.concat([df_bath_nan, df_bath_without_nan], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Square feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "      <th>BEDS</th>\n",
       "      <th>PROPERTYSQFT</th>\n",
       "      <th>SUBLOCALITY_ENCODED</th>\n",
       "      <th>TYPE_ENCODED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>899500</td>\n",
       "      <td>2</td>\n",
       "      <td>951.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>259000</td>\n",
       "      <td>3</td>\n",
       "      <td>590.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>430000</td>\n",
       "      <td>2</td>\n",
       "      <td>900.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>895000</td>\n",
       "      <td>3</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>325000</td>\n",
       "      <td>1</td>\n",
       "      <td>713.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>370000</td>\n",
       "      <td>3</td>\n",
       "      <td>440.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>1950000</td>\n",
       "      <td>2</td>\n",
       "      <td>960.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>599000</td>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>245000</td>\n",
       "      <td>1</td>\n",
       "      <td>750.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>1275000</td>\n",
       "      <td>1</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1621 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PRICE  BEDS  PROPERTYSQFT  SUBLOCALITY_ENCODED  TYPE_ENCODED\n",
       "6      899500     2         951.0                  4.0           0.0\n",
       "12     259000     3         590.0                  8.0           3.0\n",
       "13     430000     2         900.0                  8.0           3.0\n",
       "14     895000     3        1700.0                  4.0           3.0\n",
       "26     325000     1         713.0                  8.0           3.0\n",
       "...       ...   ...           ...                  ...           ...\n",
       "4791   370000     3         440.0                  4.0           3.0\n",
       "4793  1950000     2         960.0                  4.0           3.0\n",
       "4796   599000     1         800.0                  4.0           3.0\n",
       "4797   245000     1         750.0                 10.0           3.0\n",
       "4798  1275000     1         850.0                  1.0           3.0\n",
       "\n",
       "[1621 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into features (X) and target variable (y)\n",
    "X = df_sqft_without_nan.drop(columns=['PROPERTYSQFT'])\n",
    "y = df_sqft_without_nan['PROPERTYSQFT']\n",
    "test = df_sqft_nan.drop(columns=['PROPERTYSQFT'])\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.067, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(test)\n",
    "\n",
    "df_sqft_nan['PROPERTYSQFT'] = y_pred\n",
    "df_sqft_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate along rows (axis=0)\n",
    "df_sqft_concat = pd.concat([df_sqft_nan, df_sqft_without_nan], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalize Data and Clean up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SUBLOCALITY</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>PROPERTYSQFT</th>\n",
       "      <th>BEDS</th>\n",
       "      <th>BATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Condo for sale</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>315000</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Condo for sale</td>\n",
       "      <td>New York</td>\n",
       "      <td>195000000</td>\n",
       "      <td>17545.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>House for sale</td>\n",
       "      <td>Richmond County</td>\n",
       "      <td>260000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Condo for sale</td>\n",
       "      <td>New York</td>\n",
       "      <td>69000</td>\n",
       "      <td>445.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Townhouse for sale</td>\n",
       "      <td>New York</td>\n",
       "      <td>55000000</td>\n",
       "      <td>14175.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>House for sale</td>\n",
       "      <td>Kings County</td>\n",
       "      <td>690000</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Condo for sale</td>\n",
       "      <td>New York</td>\n",
       "      <td>899500</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>House for sale</td>\n",
       "      <td>Richmond County</td>\n",
       "      <td>16800000</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>8</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Co-op for sale</td>\n",
       "      <td>East Bronx</td>\n",
       "      <td>265000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Co-op for sale</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>440000</td>\n",
       "      <td>978.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TYPE      SUBLOCALITY      PRICE  PROPERTYSQFT  BEDS  BATH\n",
       "0      Condo for sale        Manhattan     315000        1400.0     2   2.0\n",
       "1      Condo for sale         New York  195000000       17545.0     7  10.0\n",
       "2      House for sale  Richmond County     260000        2015.0     4   2.0\n",
       "3      Condo for sale         New York      69000         445.0     3   1.0\n",
       "4  Townhouse for sale         New York   55000000       14175.0     7   9.0\n",
       "5      House for sale     Kings County     690000        4004.0     5   2.0\n",
       "6      Condo for sale         New York     899500         951.0     2   2.0\n",
       "7      House for sale  Richmond County   16800000       33000.0     8  16.0\n",
       "8      Co-op for sale       East Bronx     265000         750.0     1   1.0\n",
       "9      Co-op for sale         Brooklyn     440000         978.0     2   1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join based on index\n",
    "df_join = df_sqft_concat.join(df_bath_concat['BATH'], how='inner')\n",
    "\n",
    "# Sublocality decoding using original mapping because encoding was done in preprocessing notebook\n",
    "encoded_data = df_join['SUBLOCALITY_ENCODED']\n",
    "# Original mapping used for encoding\n",
    "category_to_number = {\n",
    " 'Manhattan': 0,\n",
    " 'New York County': 1,\n",
    " 'Richmond County': 2,\n",
    " 'Kings County': 3,\n",
    " 'New York': 4,\n",
    " 'East Bronx': 5,\n",
    " 'Brooklyn': 6,\n",
    " 'The Bronx': 7,\n",
    " 'Queens': 8,\n",
    " 'Staten Island': 9,\n",
    " 'Queens County': 10,\n",
    " 'Bronx County': 11,\n",
    " 'Coney Island': 12,\n",
    " 'Brooklyn Heights': 13,\n",
    " 'Jackson Heights': 14,\n",
    " 'Riverdale': 15,\n",
    " 'Rego Park': 16,\n",
    " 'Fort Hamilton': 17,\n",
    " 'Flushing': 18,\n",
    " 'Dumbo': 19,\n",
    " 'Snyder Avenue': 20\n",
    "}\n",
    "# Create a reverse mapping\n",
    "number_to_category = {v: k for k, v in category_to_number.items()}\n",
    "# Decode manually using the reverse mapping\n",
    "decoded_data = [number_to_category[num] for num in encoded_data]\n",
    "# Change New York County:1 to New york, same for Bronx County:11, and Queens County:10\n",
    "decoded_data = pd.Series(decoded_data).replace('New York County', 'New York').replace('Queens County', 'Queens').replace('Bronx County', 'Bronx').tolist()\n",
    "# Input decoded data\n",
    "df_join['SUBLOCALITY_ENCODED'] = decoded_data\n",
    "\n",
    "# Type decoding\n",
    "encoded_data = df_join['TYPE_ENCODED']\n",
    "category_to_number = {\n",
    " 'Condo for sale': 0,\n",
    " 'House for sale': 1,\n",
    " 'Townhouse for sale': 2,\n",
    " 'Co-op for sale': 3,\n",
    " 'Multi-family home for sale': 4,\n",
    " 'For sale': 5,\n",
    " 'Contingent': 6,\n",
    " 'Land for sale': 7,\n",
    " 'Foreclosure': 8,\n",
    " 'Pending': 9,\n",
    " 'Coming Soon': 10,\n",
    " 'Mobile house for sale': 11\n",
    "}\n",
    "# Create a reverse mapping\n",
    "number_to_category = {v: k for k, v in category_to_number.items()}\n",
    "# Decode manually using the reverse mapping\n",
    "decoded_data = [number_to_category[num] for num in encoded_data]\n",
    "# Input decoded data\n",
    "df_join['TYPE_ENCODED'] = decoded_data\n",
    "\n",
    "# Change header names \n",
    "df_join = df_join.rename(columns={'SUBLOCALITY_ENCODED': 'SUBLOCALITY'})\n",
    "df_join = df_join.rename(columns={'TYPE_ENCODED': 'TYPE'})\n",
    "\n",
    "# Reorder columns and sort rows for easier readability\n",
    "new_order = ['TYPE','SUBLOCALITY','PRICE','PROPERTYSQFT','BEDS','BATH']\n",
    "df_join = df_join[new_order]\n",
    "df_join = df_join.sort_index()\n",
    "#df_join.to_csv('Final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs and Plots and Neat Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
